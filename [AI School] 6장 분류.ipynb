{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification 분류\n",
    "\n",
    "1. 분류를 이해하기\n",
    "    1. Classification 특성과 알고리즘\n",
    "1. 분류의 다양한 방식을 알아보기\n",
    "    1. Logistic Regression\n",
    "    1. SoftMax\n",
    "    1. Naive Bayes\n",
    "    1. SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류이해하기\n",
    "   \n",
    "분류 : 카테고리에 분류하는 방식 // 선형회귀는 분류에 사용 될 수 없음\n",
    "\n",
    "* 분류는 0 또는 1의 값만 가지기 때문에 그 범위 이상의 값을 가질 수 없음.\n",
    "\n",
    "ex) 종양 크기를 통해 암 유무를 확인할때 선형회귀를 사용한다 치면 종용의 크기 데이터 하나의 값이 지나치게 다를경우 중간에 분류할 값을 찾기 힘들어 분류에 오류가 생김 고로 다른 모델을 사용 해야함\n",
    "https://wikidocs.net/4288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "0~1 사이의 값만 보내는 함수가 필요\n",
    "0 <= h(x) <= 1\n",
    "\n",
    "#### Sigmoid function\n",
    "![sigmoid](https://user-images.githubusercontent.com/50629716/62007357-68e43b80-b187-11e9-9e0c-e0002900a267.JPG)\n",
    "\n",
    "h(x) = P(y=1|x;0) // 1번 class에 들어갈 확률 \n",
    "\n",
    "#### Decision Boundary \n",
    "\n",
    "Hypothesis function 의 값 0.5를 기준으로 분류\n",
    "* -X값이 0보다 크면 시그모이드 함수는 1값에 가까워 지고\n",
    "* -X값이 0보다 작으면 시그모이드 함수는 0값에 가까워 진다\n",
    "\n",
    "https://wikidocs.net/4288\n",
    "\n",
    "#### Cost function\n",
    "![cost](https://user-images.githubusercontent.com/50629716/62007569-f9bc1680-b189-11e9-86a2-400f7099e62a.JPG)\n",
    "이말은 Θx값이 0보다 크거나 같으면 1로\n",
    "작으면 0으로 수렴한다\n",
    "http://gnujoow.github.io/ml/2016/01/29/ML3-Logistic-Regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function , Multinomial classfication\n",
    "\n",
    "분류를 해야할 것이 3개 이상일때 어떻게 분류할 것인가??\n",
    "\n",
    "A,B,C 3개의 클래스가 있을때\n",
    "* A인가 아닌가로 : A판별   // X - A - Y\n",
    "* B인가 아닌가로 : B판별   // X - B - Y\n",
    "* C인가 아닌가로 : C판별   // X - C - Y\n",
    "\n",
    "![soft](https://user-images.githubusercontent.com/50629716/62007964-00995800-b18f-11e9-80d7-56798ef65b15.JPG)\n",
    "\n",
    "#### Cross Entropy\n",
    "\n",
    "예측값과 Label 값이 얼마나 차이가 있는지 나타내는 척도\n",
    "![cross](https://user-images.githubusercontent.com/50629716/62008094-43a7fb00-b190-11e9-8aa7-8dfd2025a2de.JPG)\n",
    "\n",
    "Cost function을 구한 것\n",
    "\n",
    "L 은 실제값 Y는 예측값\n",
    "1. 요소끼리 곱을 진행한다\n",
    "2. 0혹은 1의 값이 나오면 맞는 것이고 무한대로 수렴하면 틀린 값\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine\n",
    "\n",
    "다양한 데이터 분포 에서도 동작하는 분류 기법중 하나이다.\n",
    "\n",
    "* 두 분류 직선을 가르는데 이 둘 사이의 거리인 마진을 최대화하는 분류 경계면을 찾는 기법.\n",
    "* SVM은 최대 마진을 가지는 선형 판별에 기초해, 속성들 간의 의존성을 고려하지https://i.imgur.com/afe8W3S.png 않는 방법\n",
    "\n",
    "####  Decision Rule\n",
    "\n",
    "우리가 그릴 street의 중심선에 직교하는 벡터 w\n",
    "![decision](https://user-images.githubusercontent.com/50629716/62038414-a18c1f80-b230-11e9-82c1-22f55393f2b8.JPG)\n",
    "\n",
    "w 와 u 의 내적을 구한 후 그 값이 어떤 상수보다 큰지 확인 하는것\n",
    "http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html\n",
    "https://ratsgo.github.io/machine%20learning/2017/05/23/SVM/\n",
    "\n",
    "SVM 증명과 원리는 나중에 자세하게 다시 한번 정리하기로 함\n",
    "(좀 많이 복잡해서 여유 있을때 정리하기로 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
